use tauri::Manager;
use tokio::runtime::Runtime;
mod grpc_client;

#[tauri::command]
async fn upload_video(file_path: String, file_id: String) -> Result<String, String> {
    // Read file and send to Python gRPC server
    let file_data = std::fs::read(&file_path).map_err(|e| e.to_string())?;
    let result = grpc_client::transcribe_video(file_id, file_data)
        .await
        .map_err(|e| e.to_string())?;
    Ok(result)
}

#[tauri::command]
async fn query_video(file_id: String, query: String) -> Result<String, String> {
    // Send query to Python gRPC server
    // Handle AI agent responses
    Ok("Response from AI agent".to_string())
}

#[tauri::command]
async fn get_transcription(file_id: String) -> Result<String, String> {
    // Get transcription from Python gRPC server
    Ok("Transcription text".to_string())
}

#[cfg_attr(mobile, tauri::mobile_entry_point)]
pub fn run() {
    tauri::Builder::default()
        .invoke_handler(tauri::generate_handler![
            upload_video,
            query_video,
            get_transcription
        ])
        .setup(|app| {
            if cfg!(debug_assertions) {
                app.handle().plugin(
                    tauri_plugin_log::Builder::default()
                        .level(log::LevelFilter::Info)
                        .build(),
                )?;
            }
            Ok(())
        })
        .run(tauri::generate_context!())
        .expect("error while running tauri application");
}